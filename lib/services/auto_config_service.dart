import 'dart:async';
import 'package:flutter/foundation.dart';
import '../models/app_models.dart';
import 'llm_config_service.dart';
import '../constants/app_constants.dart';

/// è‡ªåŠ¨é…ç½®æœåŠ¡ï¼Œè´Ÿè´£åº”ç”¨å¯åŠ¨æ—¶çš„è‡ªåŠ¨è¿æ¥å’Œé…ç½®
class AutoConfigService {
  final LLMConfigService _llmConfigService = LLMConfigService();

  /// è‡ªåŠ¨é…ç½®LLMè¿æ¥
  Future<LLMConfig?> autoConfigureLLM() async {
    try {
      debugPrint('ğŸ”„ Starting automatic LLM configuration...');

      // åˆ›å»ºé»˜è®¤é…ç½®
      final defaultConfig = LLMConfig(
        provider: 'ollama',
        serverUrl: AppConstants.defaultOllamaUrl,
        selectedModel: '',
      );

      // æµ‹è¯•è¿æ¥åˆ°OllamaæœåŠ¡å™¨
      debugPrint('ğŸ” Testing connection to Ollama...');
      final connectionResult = await _llmConfigService.testConnection(defaultConfig);
      
      if (!connectionResult['success']) {
        debugPrint('âŒ Failed to connect to Ollama: ${connectionResult['message']}');
        return null;
      }

      final availableModels = connectionResult['models'] as List<String>?;
      if (availableModels == null || availableModels.isEmpty) {
        debugPrint('âŒ No models available on Ollama server');
        return null;
      }

      debugPrint('âœ… Connected to Ollama. Available models: ${availableModels.join(', ')}');

      // é€‰æ‹©æ¨¡å‹ï¼šä¼˜å…ˆé€‰æ‹©é»˜è®¤æ¨¡å‹ï¼Œå¦åˆ™é€‰æ‹©å¤‡ç”¨æ¨¡å‹ï¼Œæœ€åé€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
      String selectedModel;
      if (availableModels.contains(AppConstants.defaultModel)) {
        selectedModel = AppConstants.defaultModel;
        debugPrint('âœ… Using preferred model: $selectedModel');
      } else if (availableModels.contains(AppConstants.fallbackModel)) {
        selectedModel = AppConstants.fallbackModel;
        debugPrint('âš ï¸ Preferred model not found, using fallback: $selectedModel');
      } else {
        selectedModel = availableModels.first;
        debugPrint('âš ï¸ Neither preferred nor fallback model found, using: $selectedModel');
      }

      final finalConfig = LLMConfig(
        provider: 'ollama',
        serverUrl: AppConstants.defaultOllamaUrl,
        selectedModel: selectedModel,
      );

      debugPrint('ğŸ‰ Auto-configuration completed successfully with model: $selectedModel');
      return finalConfig;
    } catch (error) {
      debugPrint('ğŸ’¥ Auto-configuration failed: $error');
      return null;
    }
  }
}
